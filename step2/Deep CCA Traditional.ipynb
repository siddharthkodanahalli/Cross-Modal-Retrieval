{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fada1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c380d4-4e3a-49b2-8ef4-a5963af2e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac998c0e-7b0a-453e-8110-f44e73b9c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_cca():\n",
    "    def __init__(self):\n",
    "        self.w_ = [None, None]\n",
    "        self.m_ = [None, None]\n",
    "\n",
    "    def fit(self, H1, H2, n_components):\n",
    "        r1 = 1e-4\n",
    "        r2 = 1e-4\n",
    "\n",
    "        m = H1.shape[0]\n",
    "        o1 = H1.shape[1]\n",
    "        o2 = H2.shape[1]\n",
    "\n",
    "        self.m_[0] = np.mean(H1, axis=0)\n",
    "        self.m_[1] = np.mean(H2, axis=0)\n",
    "        H1bar = H1 - np.tile(self.m_[0], (m, 1))\n",
    "        H2bar = H2 - np.tile(self.m_[1], (m, 1))\n",
    "\n",
    "        # Compute covariance matrices\n",
    "        SigmaHat12 = (1.0 / (m - 1)) * np.dot(H1bar.T, H2bar)\n",
    "        SigmaHat11 = (1.0 / (m - 1)) * np.dot(H1bar.T,\n",
    "                                              H1bar) + r1 * np.identity(o1)\n",
    "        SigmaHat22 = (1.0 / (m - 1)) * np.dot(H2bar.T,\n",
    "                                              H2bar) + r2 * np.identity(o2)\n",
    "\n",
    "        [D1, V1] = np.linalg.eigh(SigmaHat11)\n",
    "        [D2, V2] = np.linalg.eigh(SigmaHat22)\n",
    "        SigmaHat11RootInv = np.dot(\n",
    "            np.dot(V1, np.diag(D1 ** -0.5)), V1.T)\n",
    "        SigmaHat22RootInv = np.dot(\n",
    "            np.dot(V2, np.diag(D2 ** -0.5)), V2.T)\n",
    "\n",
    "        Tval = np.dot(np.dot(SigmaHat11RootInv,\n",
    "                             SigmaHat12), SigmaHat22RootInv)\n",
    "\n",
    "        [U, D, V] = np.linalg.svd(Tval)\n",
    "        V = V.T\n",
    "        self.w_[0] = np.dot(SigmaHat11RootInv, U[:, 0:n_components])\n",
    "        self.w_[1] = np.dot(SigmaHat22RootInv, V[:, 0:n_components])\n",
    "        D = D[0:n_components]\n",
    "\n",
    "    def _get_result(self, x, idx):\n",
    "        result = x - self.m_[idx].reshape([1, -1]).repeat(len(x), axis=0)\n",
    "        result = np.dot(result, self.w_[idx])\n",
    "        return result\n",
    "\n",
    "    def transform(self, H1, H2):\n",
    "        return [self._get_result(H1, 0), self._get_result(H2, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bd319b-37a4-42cc-90bd-e48638c757da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cca_loss(outdim_size, use_all_singular_values):\n",
    "    \"\"\"\n",
    "    The main loss function (inner_cca_objective) is wrapped in this function due to\n",
    "    the constraints imposed by Keras on objective functions\n",
    "    \"\"\"\n",
    "\n",
    "    def inner_cca_objective(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        It is the loss function of CCA as introduced in the original paper.\n",
    "        \"\"\"\n",
    "\n",
    "        r1 = 1e-4\n",
    "        r2 = 1e-4\n",
    "        eps = 1e-12\n",
    "        o1 = o2 = int(y_pred.shape[1] // 2)\n",
    "\n",
    "        # unpack (separate) the output of networks for view 1 and view 2\n",
    "        H1 = tf.transpose(a=y_pred[:, 0:o1])\n",
    "        H2 = tf.transpose(a=y_pred[:, o1: o1 + o2])\n",
    "        \n",
    "        \n",
    "\n",
    "        m = tf.shape(input=H1)[1]\n",
    "\n",
    "        H1bar = H1 - tf.cast(tf.divide(1, m), tf.float32) * tf.matmul(\n",
    "            H1, tf.ones([m, m])\n",
    "        )\n",
    "        H2bar = H2 - tf.cast(tf.divide(1, m), tf.float32) * tf.matmul(\n",
    "            H2, tf.ones([m, m])\n",
    "        )\n",
    "\n",
    "        SigmaHat12 = tf.cast(tf.divide(1, m - 1), tf.float32) * tf.matmul(\n",
    "            H1bar, H2bar, transpose_b=True\n",
    "        )  # [dim, dim]\n",
    "        SigmaHat11 = tf.cast(tf.divide(1, m - 1), tf.float32) * tf.matmul(\n",
    "            H1bar, H1bar, transpose_b=True\n",
    "        ) + r1 * tf.eye(o1)\n",
    "        SigmaHat22 = tf.cast(tf.divide(1, m - 1), tf.float32) * tf.matmul(\n",
    "            H2bar, H2bar, transpose_b=True\n",
    "        ) + r2 * tf.eye(o2)\n",
    "\n",
    "        # Calculating the root inverse of covariance matrices by using eigen decomposition\n",
    "        [D1, V1] = tf.linalg.eigh(SigmaHat11)\n",
    "        [D2, V2] = tf.linalg.eigh(SigmaHat22)  # Added to increase stability\n",
    "\n",
    "        posInd1 = tf.compat.v1.where(tf.greater(D1, eps))\n",
    "        D1 = tf.gather_nd(D1, posInd1)  # get eigen values that are larger than eps\n",
    "        V1 = tf.transpose(\n",
    "            a=tf.nn.embedding_lookup(params=tf.transpose(a=V1), ids=tf.squeeze(posInd1))\n",
    "        )\n",
    "\n",
    "        posInd2 = tf.compat.v1.where(tf.greater(D2, eps))\n",
    "        D2 = tf.gather_nd(D2, posInd2)\n",
    "        V2 = tf.transpose(\n",
    "            a=tf.nn.embedding_lookup(params=tf.transpose(a=V2), ids=tf.squeeze(posInd2))\n",
    "        )\n",
    "\n",
    "        SigmaHat11RootInv = tf.matmul(\n",
    "            tf.matmul(V1, tf.linalg.tensor_diag(D1 ** -0.5)), V1, transpose_b=True\n",
    "        )  # [dim, dim]\n",
    "        SigmaHat22RootInv = tf.matmul(\n",
    "            tf.matmul(V2, tf.linalg.tensor_diag(D2 ** -0.5)), V2, transpose_b=True\n",
    "        )\n",
    "\n",
    "        Tval = tf.matmul(tf.matmul(SigmaHat11RootInv, SigmaHat12), SigmaHat22RootInv)\n",
    "\n",
    "        if use_all_singular_values:\n",
    "            corr = tf.sqrt(tf.linalg.trace(tf.matmul(Tval, Tval, transpose_a=True)))\n",
    "        else:\n",
    "            [U, V] = tf.linalg.eigh(tf.matmul(Tval, Tval, transpose_a=True))\n",
    "            U = tf.gather_nd(U, tf.compat.v1.where(tf.greater(U, eps)))\n",
    "            kk = tf.reshape(tf.cast(tf.shape(input=U), tf.int32), [])\n",
    "            K = tf.minimum(kk, outdim_size)\n",
    "            w, _ = tf.nn.top_k(U, k=K)\n",
    "            corr = tf.reduce_sum(input_tensor=tf.sqrt(w))\n",
    "\n",
    "        return -corr\n",
    "\n",
    "    return inner_cca_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea70efa0-3f25-4454-bf7d-b2c3319ca341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(layer_sizes1, layer_sizes2, input_size1, input_size2, reg_lambda):\n",
    "    view1_input = keras.layers.Input(shape=(input_size1,))\n",
    "    view2_input = keras.layers.Input(shape=(input_size2,))\n",
    "    \n",
    "    view1 = view1_input\n",
    "    view2 = view2_input\n",
    "\n",
    "    for i, comp in enumerate(layer_sizes1):\n",
    "        if i == len(layer_sizes1)-1:\n",
    "            view1 = keras.layers.Dense(comp, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(reg_lambda))(view1)\n",
    "        else:\n",
    "            view1 = keras.layers.Dense(comp, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(reg_lambda))(view1)\n",
    "            \n",
    "    for i, comp in enumerate(layer_sizes2):\n",
    "        if i == len(layer_sizes2)-1:\n",
    "            view2 = keras.layers.Dense(comp, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(reg_lambda))(view2)\n",
    "        else:\n",
    "            view2 = keras.layers.Dense(comp, activation='sigmoid',kernel_regularizer=keras.regularizers.l2(reg_lambda))(view2)\n",
    "\n",
    "    merged = keras.layers.Concatenate()([view1, view2])\n",
    "    model = keras.Model(inputs=[view1_input, view2_input], outputs=merged)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(output_dir, view1_train_data, view2_train_data, view1_val_data, view2_val_data,\n",
    "                layer_sizes1, layer_sizes2, latent_size, input_size1, input_size2, \n",
    "                learning_rate, epochs, batch_size, reg_lambda):\n",
    "    \n",
    "    \n",
    "    model = get_model(layer_sizes1, layer_sizes2, input_size1, input_size2, reg_lambda)\n",
    "    sgd = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss=cca_loss(latent_size, False), optimizer=sgd)\n",
    "    \n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=output_dir +\"/\"+ 'model.h5', save_best_only=True, save_weights_only=False)\n",
    "    \n",
    "    model.fit(x=[view1_train_data, view2_train_data],y=np.zeros(len(view1_train_data)), \n",
    "              validation_data = ([view1_val_data,view2_val_data],np.zeros(len(view1_val_data))),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks = [checkpointer])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_model(model, view1_test_data, view2_test_data):\n",
    "    preds = model.predict([view1_test_data, view2_test_data])\n",
    "    \n",
    "    img_l = int(preds.shape[1] / 2)\n",
    "    text_l = 2*int(preds.shape[1] / 2)\n",
    "\n",
    "    image_embeds = preds[:,0:img_l]\n",
    "    text_embeds = preds[:,img_l:text_l]\n",
    "    l1 = linear_cca()\n",
    "    l1.fit(image_embeds,text_embeds,img_l)\n",
    "    transformed = l1.transform(image_embeds,text_embeds)\n",
    "    return (transformed[0], transformed[1])  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a968bcf-5baf-4372-8652-2dd1c836b4f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation(data_X, data_Y, data_ids, im2recipe, samples_to_draw, time_sample=10):\n",
    "    idxs = np.argsort(data_ids)\n",
    "    names = data_ids[idxs]\n",
    "    image_vecs = data_X[idxs]\n",
    "    text_vecs = data_Y[idxs]\n",
    "    idxs = range(samples_to_draw)\n",
    "    \n",
    "    glob_rank = []\n",
    "    glob_recall = {1:0.0,5:0.0,10:0.0}\n",
    "    for i in range(time_sample):\n",
    "        ids = random.sample(range(0,len(names)), samples_to_draw)\n",
    "        im_sub = image_vecs[ids,:]\n",
    "        instr_sub = text_vecs[ids,:]\n",
    "        ids_sub = names[ids]\n",
    "\n",
    "        if im2recipe:\n",
    "            sims = np.dot(im_sub,instr_sub.T) # for im2recipe\n",
    "        else:\n",
    "            sims = np.dot(instr_sub,im_sub.T) # for recipe2im\n",
    "\n",
    "        med_rank = []\n",
    "        recall = {1:0.0,5:0.0,10:0.0}\n",
    "        for ii in idxs:\n",
    "            name = ids_sub[ii]\n",
    "            # get a column of similarities\n",
    "            sim = sims[ii,:]\n",
    "\n",
    "            # sort indices in descending order\n",
    "            sorting = np.argsort(sim)[::-1].tolist()\n",
    "\n",
    "            # find where the index of the pair sample ended up in the sorting\n",
    "            pos = sorting.index(ii)\n",
    "\n",
    "            if (pos+1) == 1:\n",
    "                recall[1]+=1\n",
    "            if (pos+1) <=5:\n",
    "                recall[5]+=1\n",
    "            if (pos+1)<=10:\n",
    "                recall[10]+=1\n",
    "\n",
    "            # store the position\n",
    "            med_rank.append(pos+1)\n",
    "\n",
    "        for i in recall.keys():\n",
    "            recall[i]=recall[i]/samples_to_draw\n",
    "\n",
    "        med = np.median(med_rank)\n",
    "\n",
    "        for i in recall.keys():\n",
    "            glob_recall[i]+=recall[i]\n",
    "        glob_rank.append(med)\n",
    "\n",
    "    for i in glob_recall.keys():\n",
    "        glob_recall[i] = glob_recall[i]/time_sample\n",
    "\n",
    "    return np.average(glob_rank), glob_recall\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0fd1e-c9ac-4b58-83ee-831bf65779d6",
   "metadata": {},
   "source": [
    "### Running models on average embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92c88dc-cc57-4cd9-8c17-970dbe1e6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read\n",
      "Epoch 1/10\n",
      "550/550 [==============================] - 15s 23ms/step - loss: -4.5225 - val_loss: -5.9662\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 8s 14ms/step - loss: -7.0232 - val_loss: -6.5401\n",
      "Epoch 3/10\n",
      "550/550 [==============================] - 7s 13ms/step - loss: -7.3926 - val_loss: -6.7572\n",
      "Epoch 4/10\n",
      "550/550 [==============================] - 7s 12ms/step - loss: -7.5599 - val_loss: -6.8812\n",
      "Epoch 5/10\n",
      "550/550 [==============================] - 7s 13ms/step - loss: -7.6619 - val_loss: -6.9652\n",
      "Epoch 6/10\n",
      "550/550 [==============================] - 7s 13ms/step - loss: -7.7333 - val_loss: -7.0274\n",
      "Epoch 7/10\n",
      "550/550 [==============================] - 7s 12ms/step - loss: -7.7876 - val_loss: -7.0762\n",
      "Epoch 8/10\n",
      "550/550 [==============================] - 7s 12ms/step - loss: -7.8298 - val_loss: -7.1160\n",
      "Epoch 9/10\n",
      "550/550 [==============================] - 6s 12ms/step - loss: -7.8639 - val_loss: -7.1493\n",
      "Epoch 10/10\n",
      "550/550 [==============================] - 7s 12ms/step - loss: -7.8932 - val_loss: -7.1778\n",
      "n_comp: 10 done..!\n",
      "Epoch 1/10\n",
      "550/550 [==============================] - 10s 15ms/step - loss: -8.3062 - val_loss: -11.0789\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 6s 12ms/step - loss: -13.3818 - val_loss: -12.3251\n",
      "Epoch 3/10\n",
      "550/550 [==============================] - 6s 12ms/step - loss: -14.1877 - val_loss: -12.7801\n",
      "Epoch 4/10\n",
      "550/550 [==============================] - 6s 11ms/step - loss: -14.5433 - val_loss: -13.0359\n",
      "Epoch 5/10\n",
      "550/550 [==============================] - 6s 11ms/step - loss: -14.7590 - val_loss: -13.2080\n",
      "Epoch 6/10\n",
      "550/550 [==============================] - 6s 12ms/step - loss: -14.9047 - val_loss: -13.3350\n",
      "Epoch 7/10\n",
      "550/550 [==============================] - 6s 12ms/step - loss: -15.0173 - val_loss: -13.4346\n",
      "Epoch 8/10\n",
      "550/550 [==============================] - 6s 11ms/step - loss: -15.1024 - val_loss: -13.5154\n",
      "Epoch 9/10\n",
      "550/550 [==============================] - 7s 12ms/step - loss: -15.1743 - val_loss: -13.5832\n",
      "Epoch 10/10\n",
      "550/550 [==============================] - 6s 10ms/step - loss: -15.2342 - val_loss: -13.6411\n",
      "n_comp: 20 done..!\n",
      "Epoch 1/10\n",
      "550/550 [==============================] - 12s 19ms/step - loss: -15.8540 - val_loss: -22.3006\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 9s 17ms/step - loss: -29.0801 - val_loss: -27.0064\n",
      "Epoch 3/10\n",
      "550/550 [==============================] - 10s 19ms/step - loss: -32.1234 - val_loss: -28.3923\n",
      "Epoch 4/10\n",
      "550/550 [==============================] - 9s 17ms/step - loss: -33.2296 - val_loss: -29.0613\n",
      "Epoch 5/10\n",
      "550/550 [==============================] - 9s 16ms/step - loss: -33.8334 - val_loss: -29.4701\n",
      "Epoch 6/10\n",
      "550/550 [==============================] - 8s 15ms/step - loss: -34.2144 - val_loss: -29.7522\n",
      "Epoch 7/10\n",
      "550/550 [==============================] - 8s 15ms/step - loss: -34.4925 - val_loss: -29.9621\n",
      "Epoch 8/10\n",
      "550/550 [==============================] - 8s 15ms/step - loss: -34.6995 - val_loss: -30.1262\n",
      "Epoch 9/10\n",
      "550/550 [==============================] - 8s 15ms/step - loss: -34.8644 - val_loss: -30.2593\n",
      "Epoch 10/10\n",
      "550/550 [==============================] - 8s 15ms/step - loss: -34.9996 - val_loss: -30.3703\n",
      "n_comp: 50 done..!\n",
      "Epoch 1/10\n",
      "550/550 [==============================] - 15s 25ms/step - loss: -20.2274 - val_loss: -26.6783\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 13s 24ms/step - loss: -34.4184 - val_loss: -31.8937\n",
      "Epoch 3/10\n",
      "550/550 [==============================] - 12s 23ms/step - loss: -38.1501 - val_loss: -33.8574\n",
      "Epoch 4/10\n",
      "550/550 [==============================] - 13s 23ms/step - loss: -39.8636 - val_loss: -34.9860\n",
      "Epoch 5/10\n",
      "550/550 [==============================] - 17s 30ms/step - loss: -40.9504 - val_loss: -35.7867\n",
      "Epoch 6/10\n",
      "550/550 [==============================] - 13s 24ms/step - loss: -41.7643 - val_loss: -36.4188\n",
      "Epoch 7/10\n",
      "550/550 [==============================] - 12s 22ms/step - loss: -42.4147 - val_loss: -36.9463\n",
      "Epoch 8/10\n",
      "550/550 [==============================] - 12s 21ms/step - loss: -42.9814 - val_loss: -37.4324\n",
      "Epoch 9/10\n",
      "550/550 [==============================] - 13s 23ms/step - loss: -43.5174 - val_loss: -37.8945\n",
      "Epoch 10/10\n",
      "550/550 [==============================] - 12s 22ms/step - loss: -44.0109 - val_loss: -38.3281\n",
      "n_comp: 100 done..!\n",
      "Epoch 1/10\n",
      "550/550 [==============================] - 31s 55ms/step - loss: -23.2332 - val_loss: -28.4406\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 27s 49ms/step - loss: -35.8487 - val_loss: -32.9439\n",
      "Epoch 3/10\n",
      "550/550 [==============================] - 28s 50ms/step - loss: -39.1834 - val_loss: -34.8249\n",
      "Epoch 4/10\n",
      "550/550 [==============================] - 32s 58ms/step - loss: -40.8715 - val_loss: -36.0097\n",
      "Epoch 5/10\n",
      "550/550 [==============================] - 31s 56ms/step - loss: -42.0258 - val_loss: -36.8919\n",
      "Epoch 6/10\n",
      "550/550 [==============================] - 33s 61ms/step - loss: -42.9368 - val_loss: -37.6489\n",
      "Epoch 7/10\n",
      "550/550 [==============================] - 32s 58ms/step - loss: -43.7279 - val_loss: -38.3414\n",
      "Epoch 8/10\n",
      "550/550 [==============================] - 31s 57ms/step - loss: -44.4586 - val_loss: -38.9658\n",
      "Epoch 9/10\n",
      "550/550 [==============================] - 33s 60ms/step - loss: -45.1047 - val_loss: -39.5284\n",
      "Epoch 10/10\n",
      "550/550 [==============================] - 33s 60ms/step - loss: -45.6940 - val_loss: -40.0640\n",
      "n_comp: 200 done..!\n",
      "Epoch 1/10\n",
      "550/550 [==============================] - 204s 367ms/step - loss: -26.3912 - val_loss: -30.2770\n",
      "Epoch 2/10\n",
      "550/550 [==============================] - 214s 389ms/step - loss: -37.4580 - val_loss: -34.4451\n",
      "Epoch 3/10\n",
      "550/550 [==============================] - 204s 371ms/step - loss: -40.6843 - val_loss: -36.4276\n",
      "Epoch 4/10\n",
      "550/550 [==============================] - 202s 368ms/step - loss: -42.5113 - val_loss: -37.7938\n",
      "Epoch 5/10\n",
      "550/550 [==============================] - 206s 375ms/step - loss: -43.8640 - val_loss: -38.9196\n",
      "Epoch 6/10\n",
      "550/550 [==============================] - 217s 394ms/step - loss: -45.0153 - val_loss: -39.9276\n",
      "Epoch 7/10\n",
      "550/550 [==============================] - 234s 425ms/step - loss: -46.0524 - val_loss: -40.8828\n",
      "Epoch 8/10\n",
      "550/550 [==============================] - 247s 449ms/step - loss: -47.0620 - val_loss: -41.8607\n",
      "Epoch 9/10\n",
      "550/550 [==============================] - 242s 439ms/step - loss: -48.1133 - val_loss: -42.9283\n",
      "Epoch 10/10\n",
      "550/550 [==============================] - 228s 414ms/step - loss: -49.2760 - val_loss: -44.1262\n",
      "n_comp: 500 done..!\n"
     ]
    }
   ],
   "source": [
    "with open('/common/home/aj780/machine_learning/CCA Data/embeddings_train1.pkl','rb') as f:\n",
    "    image_data = pickle.load(f)\n",
    "    \n",
    "    \n",
    "image_train_data = image_data[0]\n",
    "text_train_data = image_data[1]\n",
    "\n",
    "\n",
    "\n",
    "with open(\"/common/home/aj780/machine_learning/CCA Data/embeddings_test1.pkl\",'rb') as f:\n",
    "    image_data = pickle.load(f)\n",
    "\n",
    "test_ids = image_data[2]\n",
    "image_test_data = image_data[0]\n",
    "text_test_data = image_data[1]\n",
    "\n",
    "\n",
    "\n",
    "with open(\"/common/home/aj780/machine_learning/CCA Data/embeddings_val1.pkl\",'rb') as f:\n",
    "    image_data = pickle.load(f)\n",
    "\n",
    "image_val_data = image_data[0]\n",
    "text_val_data = image_data[1]\n",
    "\n",
    "print(\"Data read\")\n",
    "\n",
    "n_components = [10, 20, 50, 100, 200, 500]\n",
    "i = 0\n",
    "metric_data_im2recipe = pd.DataFrame(columns = ['n_comp','medR','r@1', 'r@5','r@10'], index=range(len(n_components)))\n",
    "metric_data_recipe2im = pd.DataFrame(columns = ['n_comp','medR','r@1', 'r@5','r@10'], index=range(len(n_components)))\n",
    "embeddings_type = \"averageEmbeddings\"\n",
    "output_dir = \"CCA_Fina_Part2_withouttriplet\"\n",
    "\n",
    "embeddings_dir = output_dir + \"/\" + embeddings_type \n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "margin = 0.4\n",
    "epochs = 10\n",
    "batch_size = 512\n",
    "reg_lambda = 1e-5\n",
    "for n_comp in n_components:\n",
    "    \n",
    "    model_out_dir = embeddings_dir +  \"/\" + str(n_comp)\n",
    "    Path(model_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    layer_sizes1 = [512, n_comp]\n",
    "    layer_sizes2 = [512,n_comp]\n",
    "    \n",
    "    model = train_model(model_out_dir, image_train_data, text_train_data,\n",
    "                        image_val_data, text_val_data,layer_sizes1, layer_sizes2,\n",
    "                        n_comp, 1024, 1024,learning_rate, epochs, batch_size, reg_lambda)\n",
    "    \n",
    "    dataX, dataY = predict_model(model,image_test_data, text_test_data)\n",
    "    medR, recall = evaluation(dataX, dataY, test_ids, True , 1000, 10)\n",
    "    metric_data_im2recipe.loc[i] = [n_comp, medR, recall[1], recall[5], recall[10]]\n",
    "    \n",
    "    medR, recall = evaluation(dataX, dataY, test_ids, False , 1000, 10)\n",
    "    metric_data_recipe2im.loc[i] = [n_comp, medR, recall[1], recall[5], recall[10]]\n",
    "    \n",
    "    \n",
    "    print(\"n_comp: \" + str(n_comp) + \" done..!\")\n",
    "    i+=1\n",
    "    \n",
    "metric_data_im2recipe.to_csv(embeddings_dir + \"/metrics_\" + embeddings_type + \"_im2recipe.csv\", index=False)\n",
    "metric_data_recipe2im.to_csv(embeddings_dir + \"/metrics_\" + embeddings_type + \"_recipe2im.csv\", index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c144ad-a7a9-4495-8f2d-f59663d5cd1a",
   "metadata": {},
   "source": [
    "### Running models on ingredients embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e0985-fa1f-4166-ad5f-ce2d4be8040d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
